policy_layers: [400, 400, 400, 400]
critic_layers: [400, 400, 400]
policy_lr: 0.0001
critic_lr: 0.0001
loss_epsilon: 0.1
loss_epsilon_penalty: 0.001
loss_epsilon_mean: 0.001
loss_epsilon_stddev: 0.000001
loss_init_log_temperature: 1.0
loss_init_log_alpha_mean: 1.0
loss_init_log_alpha_stddev: 10.0
discount: 0.99
batch_size: 256
target_policy_update_period: 100
target_critic_update_period: 100
samples_per_insert: 32.0
n_step: 5
num_samples: 20
clipping: True
checkpoint: True
max_replay_size: 500000